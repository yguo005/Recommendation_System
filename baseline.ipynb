{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "MDkOb49oY-Dl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Load Amazon Beauty .inter files\n",
        "# ===========================\n",
        "def load_inter_file(path):\n",
        "    return pd.read_csv(\n",
        "        path,\n",
        "        sep=\"\\t\",  # or ' ' if space-separated\n",
        "        dtype={\"user_id\": str, \"item_id\": str, \"timestamp\": str, \"label\": int},\n",
        "        low_memory=False\n",
        "    )\n",
        "\n",
        "train_df = load_inter_file(\"amazon-beauty-train.inter\")\n",
        "val_df = load_inter_file(\"amazon-beauty-valid.inter\")   # optional\n",
        "test_df = load_inter_file(\"amazon-beauty-test.inter\")\n",
        "\n",
        "# Build last item dictionary for leave-one-out\n",
        "user_last_item = train_df.groupby(\"user_id\")[\"item_id\"].last().to_dict()"
      ],
      "metadata": {
        "id": "7V_s9yQMY8Rn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(train_df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QYLvCR3bP-T",
        "outputId": "e747e747-65cb-47a9-a9e0-6c392cc2cf76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  user_id item_id    timestamp  label\n",
            "0    2238     657  908755200.0      1\n",
            "1    2254     661  912297600.0      1\n",
            "2    2274     671  921542400.0      1\n",
            "3    2355     687  928368000.0      1\n",
            "4    2197     647  937267200.0      1\n",
            "user_id      object\n",
            "item_id      object\n",
            "timestamp    object\n",
            "label         int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-zptTezeYsoa"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Baseline Functions\n",
        "# ===========================\n",
        "\n",
        "# -------- Most Popular --------\n",
        "def most_popular(train_df, K=10):\n",
        "    \"\"\"\n",
        "    Count item frequencies (label=1) in train set and return top-K items.\n",
        "    \"\"\"\n",
        "    item_counts = train_df[train_df[\"label\"]==1][\"item_id\"].value_counts()\n",
        "    return item_counts.index[:K].tolist()\n",
        "\n",
        "\n",
        "def evaluate_most_popular(test_df, top_k_items):\n",
        "    \"\"\"\n",
        "    Evaluate HitRate@K for Most Popular baseline.\n",
        "    Only considers positive interactions (label=1).\n",
        "    \"\"\"\n",
        "    test_pos = test_df[test_df[\"label\"]==1]\n",
        "    hits = 0\n",
        "    for _, row in test_pos.iterrows():\n",
        "        if row[\"item_id\"] in top_k_items:\n",
        "            hits += 1\n",
        "    return hits / len(test_pos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Item-based KNN baseline with sparse matrix\n",
        "# ===========================\n",
        "# Map string IDs to integer indices\n",
        "user2idx = {u: i for i, u in enumerate(train_df['user_id'].unique())}\n",
        "item2idx = {i: j for j, i in enumerate(train_df['item_id'].unique())}\n",
        "idx2item = {v: k for k, v in item2idx.items()}\n",
        "\n",
        "rows = train_df['item_id'].map(item2idx)\n",
        "cols = train_df['user_id'].map(user2idx)\n",
        "data = train_df['label'].astype(float)\n",
        "\n",
        "# Build sparse item-user matrix\n",
        "sparse_matrix = csr_matrix((data, (rows, cols)), shape=(len(item2idx), len(user2idx)))\n",
        "\n",
        "# Cosine similarity (sparse)\n",
        "sim_matrix = cosine_similarity(sparse_matrix, dense_output=False)\n",
        "\n",
        "# Recommendation function\n",
        "def recommend_item_knn_sparse(sim_matrix, last_item, K=10):\n",
        "    if last_item not in item2idx:\n",
        "        return []\n",
        "    idx = item2idx[last_item]\n",
        "    sim_scores = np.array(sim_matrix[idx].toarray()).flatten()\n",
        "    top_idx = np.argsort(-sim_scores)[1:K+1]  # skip itself\n",
        "    return [idx2item[i] for i in top_idx]\n",
        "\n",
        "# Evaluate HR@K\n",
        "def evaluate_item_knn_sparse(sim_matrix, test_df, user_last_item, K=10):\n",
        "    test_pos = test_df[test_df[\"label\"]==1]\n",
        "    hits = 0\n",
        "    for _, row in test_pos.iterrows():\n",
        "        user = row[\"user_id\"]\n",
        "        true_item = row[\"item_id\"]\n",
        "        last_item = user_last_item.get(user)\n",
        "        if last_item is None:\n",
        "            continue\n",
        "        recs = recommend_item_knn_sparse(sim_matrix, last_item, K)\n",
        "        if true_item in recs:\n",
        "            hits += 1\n",
        "    return hits / len(test_pos)"
      ],
      "metadata": {
        "id": "RoLu2_TAY7uV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Run baselines\n",
        "# ===========================\n",
        "# Most Popular\n",
        "for K in [10, 20, 50]:\n",
        "    top_items = most_popular(train_df, K=K)\n",
        "    hr = evaluate_most_popular(test_df, top_items)\n",
        "    print(f\"Most Popular HR@{K}: {round(hr,4)}\")\n",
        "\n",
        "# Item-KNN\n",
        "for K in [10, 20, 50]:\n",
        "    hr = evaluate_item_knn_sparse(sim_matrix, test_df, user_last_item, K=K)\n",
        "    print(f\"Item-KNN HR@{K}: {round(hr,4)}\")\n",
        "\n",
        "# ===========================\n",
        "# Print top recommendations for first 5 users\n",
        "# ===========================\n",
        "print(\"\\nTop recommendations for first 5 users (Item-KNN, K=10):\")\n",
        "for user in list(user_last_item.keys())[:5]:\n",
        "    last_item = user_last_item[user]\n",
        "    recs = recommend_item_knn_sparse(sim_matrix, last_item, K=10)\n",
        "    print(f\"User {user}, last item {last_item}, recommended: {recs}\")\n",
        "\n",
        "# ===========================\n",
        "# Save results\n",
        "# ===========================\n",
        "results = []\n",
        "for K in [10, 20, 50]:\n",
        "    mp_hr = evaluate_most_popular(test_df, most_popular(train_df, K=K))\n",
        "    knn_hr = evaluate_item_knn_sparse(sim_matrix, test_df, user_last_item, K=K)\n",
        "    results.append({\"Model\": f\"Most Popular HR@{K}\", \"HR\": mp_hr})\n",
        "    results.append({\"Model\": f\"Item-KNN HR@{K}\", \"HR\": knn_hr})\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"baseline_results.csv\", index=False)\n",
        "print(\"\\nBaseline results saved to baseline_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcWszj2eZNhk",
        "outputId": "c7b53a51-7d19-4898-d311-15881fa09cb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Popular HR@10: 0.0077\n",
            "Most Popular HR@20: 0.0132\n",
            "Most Popular HR@50: 0.0241\n",
            "Item-KNN HR@10: 0.0123\n",
            "Item-KNN HR@20: 0.018\n",
            "Item-KNN HR@50: 0.0294\n",
            "\n",
            "Top recommendations for first 5 users (Item-KNN, K=10):\n",
            "User 1, last item 81855, recommended: ['42447', '1', '139583', '169344', '186634', '22048', '235440', '149737', '150342', '150341']\n",
            "User 10, last item 89347, recommended: ['171605', '62224', '123397', '192557', '68192', '65397', '37626', '231254', '84153', '61967']\n",
            "User 100, last item 63, recommended: ['134541', '66920', '43777', '51432', '162531', '35537', '242240', '241069', '239975', '239860']\n",
            "User 1000, last item 287, recommended: ['242240', '241069', '239975', '239860', '235450', '231477', '223801', '210788', '190804', '124416']\n",
            "User 10000, last item 906, recommended: ['2562', '15820', '13258', '60767', '189071', '57441', '57442', '31798', '63466', '56004']\n",
            "\n",
            "Baseline results saved to baseline_results.csv\n"
          ]
        }
      ]
    }
  ]
}