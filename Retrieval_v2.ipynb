{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yguo005/Recommendation_System/blob/main/Retrieval_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# PyTorch way (works if PyTorch installed)\n",
        "gpu_available = torch.cuda.is_available()\n",
        "print(\"GPU available:\", gpu_available)\n",
        "if gpu_available:\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPHjfD-HzlzX",
        "outputId": "7ad20cf3-a0d8-48a3-c67b-d25977f8ed6a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "x2kzxx2jxBDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df015abe-a93f-4cb1-91d7-749e65e89653"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_inter(path):\n",
        "    return pd.read_csv(path, sep=\"\\t\", dtype=str)\n",
        "\n",
        "df = load_inter(\"amazon-beauty-train.inter\")\n",
        "print(df.head())\n",
        "\n",
        "# Keep only positive interactions\n",
        "df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "df = df[df[\"label\"] == 1].copy()"
      ],
      "metadata": {
        "id": "gy3yVghNxBFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d92a4a7-0571-4a20-8e58-7392d60691fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  user_id item_id    timestamp label\n",
            "0    2238     657  908755200.0   1.0\n",
            "1    2254     661  912297600.0   1.0\n",
            "2    2274     671  921542400.0   1.0\n",
            "3    2355     687  928368000.0   1.0\n",
            "4    2197     647  937267200.0   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"user_idx\"] = df[\"user_id\"].astype(\"category\").cat.codes\n",
        "df[\"item_idx\"] = df[\"item_id\"].astype(\"category\").cat.codes\n",
        "\n",
        "num_users = df[\"user_idx\"].nunique()\n",
        "num_items = df[\"item_idx\"].nunique()\n",
        "\n",
        "print(\"Users:\", num_users, \"Items:\", num_items)"
      ],
      "metadata": {
        "id": "aBDLX7XIxBHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae634ef-3821-4811-905e-f8cd2462c881"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users: 1192466 Items: 210651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InterDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = torch.tensor(df[\"user_idx\"].values, dtype=torch.long)\n",
        "        self.items = torch.tensor(df[\"item_idx\"].values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx]\n",
        "\n",
        "dataset = InterDataset(df)\n",
        "loader = DataLoader(dataset, batch_size=4096, shuffle=True)"
      ],
      "metadata": {
        "id": "49DLW0EixHgC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoTower(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_dim=64):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        u = self.user_emb(user)\n",
        "        i = self.item_emb(item)\n",
        "        # Dot product\n",
        "        return (u * i).sum(dim=1)\n",
        "\n",
        "model = TwoTower(num_users, num_items, 64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "gbn35h0CxHeL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    for user, item in loader:\n",
        "        user, item = user.to(device), item.to(device)\n",
        "\n",
        "        # positive examples\n",
        "        pos_score = model(user, item)\n",
        "\n",
        "        # negative sampling\n",
        "        neg_items = torch.randint(0, num_items, item.shape, device=device)\n",
        "        neg_score = model(user, neg_items)\n",
        "\n",
        "        # labels\n",
        "        labels = torch.cat([\n",
        "            torch.ones_like(pos_score),\n",
        "            torch.zeros_like(neg_score),\n",
        "        ])\n",
        "\n",
        "        scores = torch.cat([pos_score, neg_score])\n",
        "\n",
        "        loss = criterion(scores, labels.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f} - Time: {time.time()-t0:.2f}s\")"
      ],
      "metadata": {
        "id": "Dh78rGYuxHbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f826a90c-c12b-4e6b-9ac1-42ea8ee3cbf9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 1207.6955 - Time: 30.07s\n",
            "Epoch 2/5 - Loss: 1130.8715 - Time: 29.23s\n",
            "Epoch 3/5 - Loss: 1053.5127 - Time: 29.49s\n",
            "Epoch 4/5 - Loss: 983.8007 - Time: 29.15s\n",
            "Epoch 5/5 - Loss: 922.6302 - Time: 29.10s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_emb = model.user_emb.weight.detach().cpu().numpy()\n",
        "item_emb = model.item_emb.weight.detach().cpu().numpy()\n",
        "\n",
        "np.save(\"user_embeddings.npy\", user_emb)\n",
        "np.save(\"item_embeddings.npy\", item_emb)\n",
        "\n",
        "print(\"Saved user_embeddings.npy and item_embeddings.npy\")\n"
      ],
      "metadata": {
        "id": "enk4xvqrxHZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d782db88-9219-4851-b706-98f107cbccb2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved user_embeddings.npy and item_embeddings.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dim = item_emb.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)  # inner product search\n",
        "index.add(item_emb.astype(\"float32\"))\n",
        "\n",
        "faiss.write_index(index, \"faiss_item_index.bin\")\n",
        "print(\"Saved faiss_item_index.bin\")"
      ],
      "metadata": {
        "id": "roJaFsCsxHW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed9f213-0f4b-49d8-e8b1-9f905dd006cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved faiss_item_index.bin\n"
          ]
        }
      ]
    }
  ]
}