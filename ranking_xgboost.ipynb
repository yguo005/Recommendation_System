{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking with XGBoost\n",
    "\n",
    "\n",
    "- Load Amazon Beauty train/valid/test interaction splits plus item metadata\n",
    "- Perform 1:1 negative sampling, categorical encoding, and timestamp normalization\n",
    "- Train/evaluate an XGBoost ranker with automatic GPU/CPU selection\n",
    "- Persist the trained booster and metrics under a configurable output directory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using XGBoost version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\n",
    "        \"Install xgboost (CPU or GPU build) before running.\"\n",
    "    ) from exc\n",
    "\n",
    "print(\"Using XGBoost version:\", xgb.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: dataset/amazon-beauty\n",
      "ITEM_FILE: dataset/amazon-beauty/amazon-beauty.item\n",
      "OUTPUT_DIR: saved_models\n",
      "NUM_NEG: 1\n",
      "SEED: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurable paths & hyperparameters \n",
    "\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"dataset/amazon-beauty\")\n",
    "INTER_PREFIX = os.path.join(DATA_DIR, \"amazon-beauty\")\n",
    "ITEM_FILE = os.environ.get(\"ITEM_FILE\", f\"{INTER_PREFIX}.item\")\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"saved_models\")\n",
    "NUM_NEG = int(os.environ.get(\"NUM_NEG\", 1))\n",
    "SEED = int(os.environ.get(\"SEED\", 42))\n",
    "VALID_SEED = SEED + 1\n",
    "TEST_SEED = SEED + 2\n",
    "GPU_ID = int(os.environ.get(\"GPU_ID\", 0))\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"ITEM_FILE: {ITEM_FILE}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"NUM_NEG: {NUM_NEG}\")\n",
    "print(f\"SEED: {SEED}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read RecBole interaction split (.inter).\"\"\"\n",
    "def load_interactions(split: str) -> pd.DataFrame:\n",
    "    \n",
    "    path = f\"{INTER_PREFIX}-{split}.inter\"\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    if \"label\" not in df.columns:\n",
    "        raise ValueError(f\"'label' column not found in {path}\")\n",
    "    return df\n",
    "\n",
    "\"\"\"Load item metadata and keep the fields used by the ranker.\"\"\"\n",
    "def load_item_features() -> pd.DataFrame:\n",
    "    \n",
    "    item_df = pd.read_csv(ITEM_FILE, sep=\"\\t\")\n",
    "    rename_map = {\n",
    "        \"item_id:token\": \"item_id\",\n",
    "        \"sales_rank:float\": \"sales_rank\",\n",
    "        \"price:float\": \"price\",\n",
    "        \"brand:token\": \"brand\",\n",
    "        \"categories:token_seq\": \"categories\",\n",
    "    }\n",
    "    item_df = item_df.rename(columns=rename_map)\n",
    "    return item_df[\"item_id sales_rank price brand categories\".split()]\n",
    "\n",
    "\n",
    "def extract_primary_category(cat_str: str) -> str:\n",
    "    if pd.isna(cat_str) or not str(cat_str).strip():\n",
    "        return \"Unknown\"\n",
    "    tokens = [c.strip().strip(\"'\\\"\") for c in str(cat_str).split(\",\")]\n",
    "    return tokens[0] if tokens else \"Unknown\"\n",
    "\n",
    "\"\"\"Cache positive items per user across splits for neg sampling.\"\"\"\n",
    "def build_user_pos_items(df_list):\n",
    "    \n",
    "    user_pos = defaultdict(set)\n",
    "    for df in df_list:\n",
    "        for row in df[[\"user_id\", \"item_id\"]].itertuples(index=False):\n",
    "            user_pos[row.user_id].add(row.item_id)\n",
    "    return user_pos\n",
    "\n",
    "\"\"\"Uniform negative sampling per interaction (1 negative per positive).\"\"\"\n",
    "def sample_negatives(df, user_pos_items, all_items, num_neg=1, seed=42):\n",
    "    \n",
    "    rng = random.Random(seed)\n",
    "    negatives = []\n",
    "    for row in df.itertuples(index=False):\n",
    "        user = row.user_id\n",
    "        for _ in range(num_neg):\n",
    "            while True:\n",
    "                neg_item = rng.choice(all_items)\n",
    "                if neg_item not in user_pos_items[user]:\n",
    "                    negatives.append(\n",
    "                        {\n",
    "                            \"user_id\": user,\n",
    "                            \"item_id\": neg_item,\n",
    "                            \"timestamp\": row.timestamp,\n",
    "                            \"label\": 0,\n",
    "                        }\n",
    "                    )\n",
    "                    break\n",
    "    neg_df = pd.DataFrame(negatives)\n",
    "    return pd.concat([df, neg_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(train_df, valid_df, test_df, item_df):\n",
    "    item_df = item_df.copy()\n",
    "    item_df[\"primary_category\"] = item_df[\"categories\"].apply(extract_primary_category)\n",
    "    item_df[\"price\"] = pd.to_numeric(item_df[\"price\"], errors=\"coerce\")\n",
    "    item_df[\"sales_rank\"] = pd.to_numeric(item_df[\"sales_rank\"], errors=\"coerce\")\n",
    "    item_df[\"price\"] = item_df[\"price\"].fillna(item_df[\"price\"].median()) # why median: Price distributions are often right-skewed, mean is pulled up by outliers; median is not \n",
    "    item_df[\"sales_rank\"] = item_df[\"sales_rank\"].fillna(item_df[\"sales_rank\"].median())\n",
    "    item_df[\"brand\"] = item_df[\"brand\"].fillna(\"Unknown\")\n",
    "    item_df[\"primary_category\"] = item_df[\"primary_category\"].fillna(\"Unknown\")\n",
    "\n",
    "    def merge_item_feat(df):\n",
    "        return df.merge(item_df, on=\"item_id\", how=\"left\")\n",
    "\n",
    "    train_df = merge_item_feat(train_df)\n",
    "    valid_df = merge_item_feat(valid_df)\n",
    "    test_df = merge_item_feat(test_df)\n",
    "\n",
    "    cat_cols = [\"user_id\", \"item_id\", \"brand\", \"primary_category\"]\n",
    "    # Ensure every categorical column is string before concatenation/encoding\n",
    "    for df in (train_df, valid_df, test_df):\n",
    "        for col in cat_cols:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    encoders = {col: LabelEncoder() for col in cat_cols}\n",
    "    combined = pd.concat([train_df[cat_cols], valid_df[cat_cols], test_df[cat_cols]])\n",
    "    for col in cat_cols:\n",
    "        # Step 1: FIT - Learn the mapping: This builds a vocabulary: {\"user_123\": 0, \"user_456\": 1, ...}\n",
    "        encoders[col].fit(combined[col])\n",
    "        # Step 2: TRANSFORM - Apply the mapping: This converts: \"user_123\" → 0, \"user_456\" → 1, ...\n",
    "        train_df[col + \"_idx\"] = encoders[col].transform(train_df[col])\n",
    "        valid_df[col + \"_idx\"] = encoders[col].transform(valid_df[col])\n",
    "        test_df[col + \"_idx\"] = encoders[col].transform(test_df[col])\n",
    "\n",
    "    for df in (train_df, valid_df, test_df):\n",
    "        df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\").fillna(0)\n",
    "        df[\"timestamp_days\"] = (df[\"timestamp\"] / 86400).astype(np.float32) #converts Unix timestamps (seconds since epoch) to days, Other features (e.g., price, sales_rank) are on different scales(price: 25.99 small scale, if use timestamps is large scale:1388534400) \n",
    "\n",
    "    feature_cols = [\n",
    "        \"user_id_idx\",\n",
    "        \"item_id_idx\",\n",
    "        \"price\",\n",
    "        \"sales_rank\",\n",
    "        \"brand_idx\",\n",
    "        \"primary_category_idx\",\n",
    "        \"timestamp_days\",\n",
    "    ]\n",
    "\n",
    "    return train_df, valid_df, test_df, feature_cols\n",
    "\n",
    "\"\"\"Auto-select GPU or CPU device (XGBoost 3.1+ API).\"\"\"\n",
    "def detect_device():\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"nvidia-smi\"], capture_output=True, text=True, timeout=2, check=False\n",
    "        )\n",
    "        gpu_present = result.returncode == 0\n",
    "    except FileNotFoundError:\n",
    "        gpu_present = False\n",
    "    except Exception:\n",
    "        gpu_present = False\n",
    "\n",
    "    if gpu_present:\n",
    "        device = f\"cuda:{GPU_ID}\"\n",
    "        print(f\"GPU detected - using device={device}\")\n",
    "        return device\n",
    "    else:\n",
    "        print(\"No GPU detected - using device=cpu\")\n",
    "        return \"cpu\"\n",
    "\n",
    "\n",
    "def train_xgboost(train_df, valid_df, feature_cols):\n",
    "    train_dmatrix = xgb.DMatrix(train_df[feature_cols], label=train_df[\"label\"])\n",
    "    valid_dmatrix = xgb.DMatrix(valid_df[feature_cols], label=valid_df[\"label\"])\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\", # binary classification with logistic regression output (probabilities 0 to 1 via sigmoid)\n",
    "        \"eval_metric\": [\"auc\", \"logloss\"], # area under ROC curve (AUC) (higher is better, 0-1), LogLoss (lower is better)\n",
    "        \"device\": detect_device(), \n",
    "        \"tree_method\": \"hist\", # histogram method (works for both CPU and GPU in 3.1+)\n",
    "        \"eta\": 0.05, # learning rate\n",
    "        \"max_depth\": 8, # Maximum depth of each tree\n",
    "        \"subsample\": 0.8, # Fraction of training samples used per tree (Uses 80% of rows per tree)\n",
    "        \"colsample_bytree\": 0.8, # Fraction of features used per tree\n",
    "        \"min_child_weight\": 3, #Minimum sum of instance weights (Hessian) in a child node, for binary classification, roughly minimum samples per leaf, prevents splits that create very small leaves\n",
    "        \"lambda\": 1.0, # L2 regularization on leaf weights, penalizes large leaf values, prevents overfitting\n",
    "    }\n",
    "    evals = [(train_dmatrix, \"train\"), (valid_dmatrix, \"valid\")]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        train_dmatrix,\n",
    "        num_boost_round=500,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=30,\n",
    "        verbose_eval=50, # Print metrics every 50 rounds\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, df, feature_cols):\n",
    "    dmatrix = xgb.DMatrix(df[feature_cols])\n",
    "    preds = model.predict(dmatrix)\n",
    "    # Clip predictions to avoid log(0) issues\n",
    "    preds_clipped = np.clip(preds, 1e-15, 1 - 1e-15)\n",
    "    auc = roc_auc_score(df[\"label\"], preds)\n",
    "    ll = log_loss(df[\"label\"], preds_clipped)\n",
    "    return {\"AUC\": float(auc), \"LogLoss\": float(ll)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    print(\"Loading interactions + metadata\")\n",
    "    train_df = load_interactions(\"train\")\n",
    "    valid_df = load_interactions(\"valid\")\n",
    "    test_df = load_interactions(\"test\")\n",
    "    item_df = load_item_features()\n",
    "\n",
    "    print(f\"Sampling {NUM_NEG}:1 negatives per positive\")\n",
    "    all_items = item_df[\"item_id\"].unique().tolist()\n",
    "    user_pos_items = build_user_pos_items([train_df, valid_df, test_df])\n",
    "    train_df_ns = sample_negatives(train_df, user_pos_items, all_items, NUM_NEG, SEED)\n",
    "    valid_df_ns = sample_negatives(valid_df, user_pos_items, all_items, NUM_NEG, VALID_SEED)\n",
    "    test_df_ns = sample_negatives(test_df, user_pos_items, all_items, NUM_NEG, TEST_SEED)\n",
    "\n",
    "    print(\"Encoding categorical + numerical features\")\n",
    "    train_df_enc, valid_df_enc, test_df_enc, feature_cols = encode_features(\n",
    "        train_df_ns, valid_df_ns, test_df_ns, item_df\n",
    "    )\n",
    "\n",
    "    print(\"Training XGBoost\")\n",
    "    model = train_xgboost(train_df_enc, valid_df_enc, feature_cols)\n",
    "\n",
    "    print(\"Evaluating\")\n",
    "    train_metrics = evaluate_model(model, train_df_enc, feature_cols)\n",
    "    valid_metrics = evaluate_model(model, valid_df_enc, feature_cols)\n",
    "    test_metrics = evaluate_model(model, test_df_enc, feature_cols)\n",
    "\n",
    "    results = {\n",
    "        \"train\": train_metrics,\n",
    "        \"valid\": valid_metrics,\n",
    "        \"test\": test_metrics,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"params\": {\n",
    "            \"num_neg\": NUM_NEG,\n",
    "            \"seed\": SEED,\n",
    "            \"tree_method\": model.attributes().get(\"tree_method\", \"unknown\"),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"ranking_xgboost.model\")\n",
    "    metrics_path = os.path.join(OUTPUT_DIR, \"ranking_xgboost_results.json\")\n",
    "\n",
    "    model.save_model(model_path)\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(json.dumps(results, indent=2))\n",
    "    print(f\"\\nModel saved to: {model_path}\")\n",
    "    print(f\"Metrics saved to: {metrics_path}\")\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading interactions + metadata\n",
      "Sampling 1:1 negatives per positive\n",
      "Encoding categorical + numerical features\n",
      "Training XGBoost\n",
      "GPU detected - using device=cuda:0\n",
      "[0]\ttrain-auc:1.00000\ttrain-logloss:0.64440\tvalid-auc:1.00000\tvalid-logloss:0.64440\n",
      "[50]\ttrain-auc:1.00000\ttrain-logloss:0.03915\tvalid-auc:1.00000\tvalid-logloss:0.03915\n",
      "[100]\ttrain-auc:1.00000\ttrain-logloss:0.00315\tvalid-auc:1.00000\tvalid-logloss:0.00315\n",
      "[150]\ttrain-auc:1.00000\ttrain-logloss:0.00026\tvalid-auc:1.00000\tvalid-logloss:0.00026\n",
      "[200]\ttrain-auc:1.00000\ttrain-logloss:0.00002\tvalid-auc:1.00000\tvalid-logloss:0.00002\n",
      "[250]\ttrain-auc:1.00000\ttrain-logloss:0.00000\tvalid-auc:1.00000\tvalid-logloss:0.00000\n",
      "[286]\ttrain-auc:1.00000\ttrain-logloss:0.00000\tvalid-auc:1.00000\tvalid-logloss:0.00000\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3051354/3843858095.py:43: UserWarning: [14:34:27] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  model.save_model(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"train\": {\n",
      "    \"AUC\": 1.0,\n",
      "    \"LogLoss\": 2.384188633191098e-06\n",
      "  },\n",
      "  \"valid\": {\n",
      "    \"AUC\": 1.0,\n",
      "    \"LogLoss\": 2.384188633191085e-06\n",
      "  },\n",
      "  \"test\": {\n",
      "    \"AUC\": 1.0,\n",
      "    \"LogLoss\": 2.3841886331910874e-06\n",
      "  },\n",
      "  \"feature_cols\": [\n",
      "    \"user_id_idx\",\n",
      "    \"item_id_idx\",\n",
      "    \"price\",\n",
      "    \"sales_rank\",\n",
      "    \"brand_idx\",\n",
      "    \"primary_category_idx\",\n",
      "    \"timestamp_days\"\n",
      "  ],\n",
      "  \"params\": {\n",
      "    \"num_neg\": 1,\n",
      "    \"seed\": 42,\n",
      "    \"tree_method\": \"unknown\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Model saved to: saved_models/ranking_xgboost.model\n",
      "Metrics saved to: saved_models/ranking_xgboost_results.json\n",
      "CPU times: user 33.4 s, sys: 2.11 s, total: 35.5 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = run_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC = 1.0 on train, valid, AND test don't seem correct, perfect scores.\n",
    "\n",
    "# The model might memorize (user_id, item_id) pairs rather than learning preferences:\n",
    "# Positive samples: Real interactions — specific (user, item) combinations\n",
    "# Negative samples: Random items the user never interacted with\n",
    "# XGBoost could trivially learn: These exact (user_id_idx, item_id_idx) combos are positive; everything else is negative. \n",
    "# since validation/test use the same random negative strategy, it generalizes perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment: Remove user_id_idx and item_id_idx\n",
    "\n",
    "# The previous run showed **AUC = 1.0** on all splits, which indicates data leakage. The model memorized (user, item) pairs instead of learning generalizable patterns.\n",
    "\n",
    "# **Hypothesis**: Removing `user_id_idx` and `item_id_idx` will force the model to learn from content features only (price, sales_rank, brand, category, timestamp), resulting in realistic performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: Content-only features (no user/item IDs)\n",
    "def run_experiment_no_ids():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXPERIMENT: XGBoost with content features only (no IDs)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nLoading interactions + metadata\")\n",
    "    train_df = load_interactions(\"train\")\n",
    "    valid_df = load_interactions(\"valid\")\n",
    "    test_df = load_interactions(\"test\")\n",
    "    item_df = load_item_features()\n",
    "\n",
    "    print(f\"Sampling {NUM_NEG}:1 negatives per positive\")\n",
    "    all_items = item_df[\"item_id\"].unique().tolist()\n",
    "    user_pos_items = build_user_pos_items([train_df, valid_df, test_df])\n",
    "    train_df_ns = sample_negatives(train_df, user_pos_items, all_items, NUM_NEG, SEED)\n",
    "    valid_df_ns = sample_negatives(valid_df, user_pos_items, all_items, NUM_NEG, VALID_SEED)\n",
    "    test_df_ns = sample_negatives(test_df, user_pos_items, all_items, NUM_NEG, TEST_SEED)\n",
    "\n",
    "    print(\"Encoding features\")\n",
    "    train_df_enc, valid_df_enc, test_df_enc, _ = encode_features(\n",
    "        train_df_ns, valid_df_ns, test_df_ns, item_df\n",
    "    )\n",
    "\n",
    "    # Content-only features (REMOVED user_id_idx and item_id_idx)\n",
    "    feature_cols_no_ids = [\n",
    "        \"price\",\n",
    "        \"sales_rank\",\n",
    "        \"brand_idx\",\n",
    "        \"primary_category_idx\",\n",
    "        \"timestamp_days\",\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nFeatures used: {feature_cols_no_ids}\")\n",
    "    print(f\"Number of features: {len(feature_cols_no_ids)}\")\n",
    "\n",
    "    print(\"\\nTraining XGBoost (content features only)\")\n",
    "    model = train_xgboost(train_df_enc, valid_df_enc, feature_cols_no_ids)\n",
    "\n",
    "    print(\"\\nEvaluating\")\n",
    "    train_metrics = evaluate_model(model, train_df_enc, feature_cols_no_ids)\n",
    "    valid_metrics = evaluate_model(model, valid_df_enc, feature_cols_no_ids)\n",
    "    test_metrics = evaluate_model(model, test_df_enc, feature_cols_no_ids)\n",
    "\n",
    "    results = {\n",
    "        \"experiment\": \"content_features_only\",\n",
    "        \"train\": train_metrics,\n",
    "        \"valid\": valid_metrics,\n",
    "        \"test\": test_metrics,\n",
    "        \"feature_cols\": feature_cols_no_ids,\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESULTS (Content Features Only)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(results, indent=2))\n",
    "    \n",
    "    # Save experiment results\n",
    "    exp_path = os.path.join(OUTPUT_DIR, \"ranking_xgboost_no_ids_results.json\")\n",
    "    with open(exp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nSaved to: {exp_path}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT: XGBoost with content features only (no IDs)\n",
      "============================================================\n",
      "\n",
      "Loading interactions + metadata\n",
      "Sampling 1:1 negatives per positive\n",
      "Encoding features\n",
      "\n",
      "Features used: ['price', 'sales_rank', 'brand_idx', 'primary_category_idx', 'timestamp_days']\n",
      "Number of features: 5\n",
      "\n",
      "Training XGBoost (content features only)\n",
      "GPU detected - using device=cuda:0\n",
      "[0]\ttrain-auc:1.00000\ttrain-logloss:0.64440\tvalid-auc:1.00000\tvalid-logloss:0.64440\n",
      "[50]\ttrain-auc:1.00000\ttrain-logloss:0.03915\tvalid-auc:1.00000\tvalid-logloss:0.03915\n",
      "[100]\ttrain-auc:1.00000\ttrain-logloss:0.00315\tvalid-auc:1.00000\tvalid-logloss:0.00315\n",
      "[150]\ttrain-auc:1.00000\ttrain-logloss:0.00026\tvalid-auc:1.00000\tvalid-logloss:0.00026\n",
      "[200]\ttrain-auc:1.00000\ttrain-logloss:0.00002\tvalid-auc:1.00000\tvalid-logloss:0.00002\n",
      "[250]\ttrain-auc:1.00000\ttrain-logloss:0.00000\tvalid-auc:1.00000\tvalid-logloss:0.00000\n",
      "[286]\ttrain-auc:1.00000\ttrain-logloss:0.00000\tvalid-auc:1.00000\tvalid-logloss:0.00000\n",
      "\n",
      "Evaluating\n",
      "\n",
      "============================================================\n",
      "RESULTS (Content Features Only)\n",
      "============================================================\n",
      "{\n",
      "  \"experiment\": \"content_features_only\",\n",
      "  \"train\": {\n",
      "    \"AUC\": 1.0,\n",
      "    \"LogLoss\": 2.384188633191098e-06\n",
      "  },\n",
      "  \"valid\": {\n",
      "    \"AUC\": 1.0,\n",
      "    \"LogLoss\": 2.384188633191085e-06\n",
      "  },\n",
      "  \"test\": {\n",
      "    \"AUC\": 1.0,\n",
      "    \"LogLoss\": 2.3841886331910874e-06\n",
      "  },\n",
      "  \"feature_cols\": [\n",
      "    \"price\",\n",
      "    \"sales_rank\",\n",
      "    \"brand_idx\",\n",
      "    \"primary_category_idx\",\n",
      "    \"timestamp_days\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Saved to: saved_models/ranking_xgboost_no_ids_results.json\n",
      "CPU times: user 32.8 s, sys: 1.37 s, total: 34.2 s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exp_results = run_experiment_no_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 2: Negatives from Items with Interactions Only\n",
    "\n",
    "# The previous experiment still showed AUC = 1.0 because:\n",
    "# - **Positive items** = Items someone bought (have good sales_rank, popular brands)\n",
    "# - **Random negatives** = Many \"dead\" items nobody ever bought\n",
    "\n",
    "# **Fix**: Sample negatives only from items that have at least one interaction. \n",
    "# This creates a more realistic task: Given two items that people actually buy, which one will this user prefer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Sample negatives only from items with interactions\n",
    "def sample_negatives_from_interacted(df, user_pos_items, interacted_items, num_neg=1, seed=42):\n",
    "    \"\"\"Sample negatives only from items that have at least one interaction.\n",
    "    \n",
    "    This creates realistic negatives: instead of random catalog items (many \"dead\"),\n",
    "    we sample from items that OTHER users have bought.\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    interacted_list = list(interacted_items)\n",
    "    negatives = []\n",
    "    \n",
    "    for row in df.itertuples(index=False):\n",
    "        user = row.user_id\n",
    "        for _ in range(num_neg):\n",
    "            attempts = 0\n",
    "            while attempts < 100:  # Prevent infinite loop\n",
    "                neg_item = rng.choice(interacted_list)\n",
    "                if neg_item not in user_pos_items[user]:\n",
    "                    negatives.append({\n",
    "                        \"user_id\": user,\n",
    "                        \"item_id\": neg_item,\n",
    "                        \"timestamp\": row.timestamp,\n",
    "                        \"label\": 0,\n",
    "                    })\n",
    "                    break\n",
    "                attempts += 1\n",
    "    \n",
    "    neg_df = pd.DataFrame(negatives)\n",
    "    return pd.concat([df, neg_df], ignore_index=True)\n",
    "\n",
    "\n",
    "def run_experiment_hard_negatives():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"EXPERIMENT 2: Negatives from items with interactions only\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nLoading interactions + metadata\")\n",
    "    train_df = load_interactions(\"train\")\n",
    "    valid_df = load_interactions(\"valid\")\n",
    "    test_df = load_interactions(\"test\")\n",
    "    item_df = load_item_features()\n",
    "\n",
    "    # Get items that have at least one interaction (across all splits)\n",
    "    all_interacted_items = set(train_df[\"item_id\"].unique()) | \\\n",
    "                           set(valid_df[\"item_id\"].unique()) | \\\n",
    "                           set(test_df[\"item_id\"].unique())\n",
    "    \n",
    "    all_catalog_items = set(item_df[\"item_id\"].unique())\n",
    "    \n",
    "    print(f\"\\nItem statistics:\")\n",
    "    print(f\"  Total items in catalog: {len(all_catalog_items):,}\")\n",
    "    print(f\"  Items with ≥1 interaction: {len(all_interacted_items):,}\")\n",
    "    print(f\"  Items with 0 interactions: {len(all_catalog_items - all_interacted_items):,}\")\n",
    "    print(f\"  Negatives will be sampled from {len(all_interacted_items):,} 'real' items\")\n",
    "\n",
    "    user_pos_items = build_user_pos_items([train_df, valid_df, test_df])\n",
    "    \n",
    "    print(f\"\\nSampling {NUM_NEG}:1 hard negatives (from interacted items only)\")\n",
    "    train_df_ns = sample_negatives_from_interacted(train_df, user_pos_items, all_interacted_items, NUM_NEG, SEED)\n",
    "    valid_df_ns = sample_negatives_from_interacted(valid_df, user_pos_items, all_interacted_items, NUM_NEG, VALID_SEED)\n",
    "    test_df_ns = sample_negatives_from_interacted(test_df, user_pos_items, all_interacted_items, NUM_NEG, TEST_SEED)\n",
    "\n",
    "    # convert item_id to string in all dataframes before merge\n",
    "    for df in (train_df_ns, valid_df_ns, test_df_ns):\n",
    "        df[\"item_id\"] = df[\"item_id\"].astype(str)\n",
    "    item_df[\"item_id\"] = item_df[\"item_id\"].astype(str)\n",
    "\n",
    "    print(\"Encoding features\")\n",
    "    train_df_enc, valid_df_enc, test_df_enc, _ = encode_features(\n",
    "        train_df_ns, valid_df_ns, test_df_ns, item_df\n",
    "    )\n",
    "\n",
    "    # Test both feature sets\n",
    "    feature_cols_with_ids = [\n",
    "        \"user_id_idx\", \"item_id_idx\", \"price\", \"sales_rank\",\n",
    "        \"brand_idx\", \"primary_category_idx\", \"timestamp_days\",\n",
    "    ]\n",
    "    feature_cols_no_ids = [\n",
    "        \"price\", \"sales_rank\", \"brand_idx\", \"primary_category_idx\", \"timestamp_days\",\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # --- With IDs ---\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"Training XGBoost WITH user/item IDs\")\n",
    "    print(\"-\" * 50)\n",
    "    model_ids = train_xgboost(train_df_enc, valid_df_enc, feature_cols_with_ids)\n",
    "    results[\"with_ids\"] = {\n",
    "        \"train\": evaluate_model(model_ids, train_df_enc, feature_cols_with_ids),\n",
    "        \"valid\": evaluate_model(model_ids, valid_df_enc, feature_cols_with_ids),\n",
    "        \"test\": evaluate_model(model_ids, test_df_enc, feature_cols_with_ids),\n",
    "    }\n",
    "    \n",
    "    # --- Without IDs ---\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"Training XGBoost WITHOUT user/item IDs (content only)\")\n",
    "    print(\"-\" * 50)\n",
    "    model_no_ids = train_xgboost(train_df_enc, valid_df_enc, feature_cols_no_ids)\n",
    "    results[\"without_ids\"] = {\n",
    "        \"train\": evaluate_model(model_no_ids, train_df_enc, feature_cols_no_ids),\n",
    "        \"valid\": evaluate_model(model_no_ids, valid_df_enc, feature_cols_no_ids),\n",
    "        \"test\": evaluate_model(model_no_ids, test_df_enc, feature_cols_no_ids),\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESULTS COMPARISON (Hard Negatives)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\n WITH user/item IDs:\")\n",
    "    print(f\"   Train AUC: {results['with_ids']['train']['AUC']:.4f}\")\n",
    "    print(f\"   Valid AUC: {results['with_ids']['valid']['AUC']:.4f}\")\n",
    "    print(f\"   Test AUC:  {results['with_ids']['test']['AUC']:.4f}\")\n",
    "    \n",
    "    print(\"\\n WITHOUT user/item IDs (content only):\")\n",
    "    print(f\"   Train AUC: {results['without_ids']['train']['AUC']:.4f}\")\n",
    "    print(f\"   Valid AUC: {results['without_ids']['valid']['AUC']:.4f}\")\n",
    "    print(f\"   Test AUC:  {results['without_ids']['test']['AUC']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    exp_path = os.path.join(OUTPUT_DIR, \"ranking_xgboost_hard_negatives.json\")\n",
    "    with open(exp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nSaved to: {exp_path}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENT 2: Negatives from items with interactions only\n",
      "======================================================================\n",
      "\n",
      "Loading interactions + metadata\n",
      "\n",
      "Item statistics:\n",
      "  Total items in catalog: 259,204\n",
      "  Items with ≥1 interaction: 249,274\n",
      "  Items with 0 interactions: 259,204\n",
      "  Negatives will be sampled from 249,274 'real' items\n",
      "\n",
      "Sampling 1:1 hard negatives (from interacted items only)\n",
      "Encoding features\n",
      "\n",
      "--------------------------------------------------\n",
      "Training XGBoost WITH user/item IDs\n",
      "--------------------------------------------------\n",
      "GPU detected - using device=cuda:0\n",
      "[0]\ttrain-auc:0.84247\ttrain-logloss:0.67497\tvalid-auc:0.61984\tvalid-logloss:0.68855\n",
      "[50]\ttrain-auc:0.87601\ttrain-logloss:0.48003\tvalid-auc:0.63635\tvalid-logloss:0.68322\n",
      "[55]\ttrain-auc:0.87654\ttrain-logloss:0.47719\tvalid-auc:0.63624\tvalid-logloss:0.68435\n",
      "\n",
      "--------------------------------------------------\n",
      "Training XGBoost WITHOUT user/item IDs (content only)\n",
      "--------------------------------------------------\n",
      "GPU detected - using device=cuda:0\n",
      "[0]\ttrain-auc:0.50000\ttrain-logloss:0.69315\tvalid-auc:0.50000\tvalid-logloss:0.69315\n",
      "[30]\ttrain-auc:0.50000\ttrain-logloss:0.69315\tvalid-auc:0.50000\tvalid-logloss:0.69315\n",
      "\n",
      "======================================================================\n",
      "RESULTS COMPARISON (Hard Negatives)\n",
      "======================================================================\n",
      "\n",
      " WITH user/item IDs:\n",
      "   Train AUC: 0.8765\n",
      "   Valid AUC: 0.6362\n",
      "   Test AUC:  0.6402\n",
      "\n",
      " WITHOUT user/item IDs (content only):\n",
      "   Train AUC: 0.5000\n",
      "   Valid AUC: 0.5000\n",
      "   Test AUC:  0.5000\n",
      "\n",
      "Saved to: saved_models/ranking_xgboost_hard_negatives.json\n",
      "CPU times: user 34.5 s, sys: 1.45 s, total: 35.9 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hard_neg_results = run_experiment_hard_negatives()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH user/item IDs: AUC = 0.64 (Valid/Test)\n",
    "# Train AUC = 0.877: Model memorizes some (user, item) patterns\n",
    "# Valid/Test AUC = 0.636: Generalizes moderately to unseen data\n",
    "# Gap (0.877 to 0.636): might be overfitting, but still useful\n",
    "# the model learns collaborative filtering patterns: which users tend to buy which items\n",
    "# This seems to be a reasonable baseline for a ranking model. Test AUC of 0.64 means the model ranks the true positive item higher than a random negative 64% of the time.\n",
    "\n",
    "# WITHOUT user/item IDs: AUC = 0.500\n",
    "# AUC = 0.5: Random guessing \n",
    "# Content features alone (price, sales_rank, brand, category, timestamp) provide zero predictive signal for user preferences\n",
    "# Two items that different users bought have similar content features (both are \"real\" products people buy). Without knowing WHO the user is and WHICH item it is, content features can't distinguish preference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys GPU",
   "language": "python",
   "name": "recsys_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
